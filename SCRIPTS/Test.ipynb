{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import urllib.request\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Chrome options\n",
    "\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")  # Optional: run Chrome in headless mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Chrome options\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")  # Optional: run Chrome in headless mode\n",
    "\n",
    "# Specify the path to your chromedriver\n",
    "chrome_driver_path = \"/Users/selahmitchell/Downloads/chromedriver-mac-arm64 2/chromedriver\"  # Update with your path\n",
    "\n",
    "# Set up the Service for ChromeDriver\n",
    "service = Service(chrome_driver_path)\n",
    "\n",
    "# Initialize the WebDriver with both Service and Options\n",
    "driver = webdriver.Chrome(service=service, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log in to Instagram\n",
    "driver.get(\"https://www.instagram.com/\")\n",
    "driver.maximize_window()\n",
    "time.sleep(5)\n",
    "\n",
    "# Log in with credentials\n",
    "my_user = \"selah.cheese\"  # Replace with your Instagram username\n",
    "my_pwd = \"M21mitc$12345\"  # Replace with your Instagram password\n",
    "\n",
    "# Log in process\n",
    "user_name = driver.find_element(By.XPATH, \"//input[@name='username']\")\n",
    "user_name.send_keys(my_user)\n",
    "user_name.send_keys(Keys.ENTER)\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "password = driver.find_element(By.XPATH, \"//input[@name='password']\")\n",
    "password.send_keys(my_pwd)\n",
    "password.send_keys(Keys.ENTER)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.instagram.com/accounts/onetap/?next=%2F\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "WebDriverWait(driver, 10).until(EC.url_contains(\"instagram.com\"))\n",
    "\n",
    "# Check if we are logged in successfully (you can check for your profile name on the page)\n",
    "print(driver.current_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Not Now' pop-up not found or already dismissed\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    not_now_button = WebDriverWait(driver, 5).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//button[text()='Not Now']\"))\n",
    "    )\n",
    "    not_now_button.click()\n",
    "    print(\"Dismissed 'Not Now' pop-up\")\n",
    "except:\n",
    "    print(\"'Not Now' pop-up not found or already dismissed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Go to the user's profile page\n",
    "profile_username = \"siblingsordating\"  # Replace with the Instagram account username\n",
    "driver.get(f\"https://www.instagram.com/{profile_username}/\")\n",
    "time.sleep(3)\n",
    "print(driver.current_url)\n",
    "\n",
    "images = driver.find_elements(By.XPATH,\"//img[@class='_aagt']\")\n",
    "\n",
    "# In[31]:\n",
    "\n",
    "my_images = set()\n",
    "\n",
    "while True:\n",
    "    for image in images:\n",
    "        source = image.get_attribute('src')\n",
    "        my_images.add(source)\n",
    "    driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "    sleep(3)\n",
    "    images = driver.find_elements(By.XPATH,\"//img[@class='_aagt']\")\n",
    "    if len(my_images)>10:\n",
    "        break\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "import wget\n",
    "\n",
    "for image in my_images:\n",
    "    wget.download(image,dest_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /opt/homebrew/Caskroom/miniconda/base/envs/ds4003/lib/python3.8/site-packages (4.26.1)\n",
      "Requirement already satisfied: pillow in /opt/homebrew/Caskroom/miniconda/base/envs/ds4003/lib/python3.8/site-packages (10.0.1)\n",
      "Collecting webdriver-manager\n",
      "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/Caskroom/miniconda/base/envs/ds4003/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /opt/homebrew/Caskroom/miniconda/base/envs/ds4003/lib/python3.8/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.26.18)\n",
      "Requirement already satisfied: trio~=0.17 in /opt/homebrew/Caskroom/miniconda/base/envs/ds4003/lib/python3.8/site-packages (from selenium) (0.27.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /opt/homebrew/Caskroom/miniconda/base/envs/ds4003/lib/python3.8/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /opt/homebrew/Caskroom/miniconda/base/envs/ds4003/lib/python3.8/site-packages (from selenium) (2024.8.30)\n",
      "Collecting typing_extensions~=4.9 (from selenium)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: websocket-client~=1.8 in /opt/homebrew/Caskroom/miniconda/base/envs/ds4003/lib/python3.8/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Caskroom/miniconda/base/envs/ds4003/lib/python3.8/site-packages (from webdriver-manager) (2.31.0)\n",
      "Collecting python-dotenv (from webdriver-manager)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/Caskroom/miniconda/base/envs/ds4003/lib/python3.8/site-packages (from webdriver-manager) (23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniconda/base/envs/ds4003/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniconda/base/envs/ds4003/lib/python3.8/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/homebrew/Caskroom/miniconda/base/envs/ds4003/lib/python3.8/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /opt/homebrew/Caskroom/miniconda/base/envs/ds4003/lib/python3.8/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniconda/base/envs/ds4003/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/ds4003/lib/python3.8/site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in /opt/homebrew/Caskroom/miniconda/base/envs/ds4003/lib/python3.8/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /opt/homebrew/Caskroom/miniconda/base/envs/ds4003/lib/python3.8/site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in /opt/homebrew/Caskroom/miniconda/base/envs/ds4003/lib/python3.8/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/ds4003/lib/python3.8/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /opt/homebrew/Caskroom/miniconda/base/envs/ds4003/lib/python3.8/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /opt/homebrew/Caskroom/miniconda/base/envs/ds4003/lib/python3.8/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /opt/homebrew/Caskroom/miniconda/base/envs/ds4003/lib/python3.8/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/ds4003/lib/python3.8/site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /opt/homebrew/Caskroom/miniconda/base/envs/ds4003/lib/python3.8/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: typing_extensions, python-dotenv, webdriver-manager\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.5.0\n",
      "    Uninstalling typing_extensions-4.5.0:\n",
      "      Successfully uninstalled typing_extensions-4.5.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-macos 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.12.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed python-dotenv-1.0.1 typing_extensions-4.12.2 webdriver-manager-4.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium pillow webdriver-manager pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping carousel images, attempt 1...\n"
     ]
    },
    {
     "ename": "TimeoutException",
     "evalue": "Message: \n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 122\u001b[0m\n\u001b[1;32m    119\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(path)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Start scraping and capturing carousel images only\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m image_data \u001b[38;5;241m=\u001b[39m \u001b[43mscroll_and_capture_carousel_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_images\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscroll_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# Convert the collected image file paths to a pandas DataFrame\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 107\u001b[0m, in \u001b[0;36mscroll_and_capture_carousel_images\u001b[0;34m(max_images, scroll_max)\u001b[0m\n\u001b[1;32m    104\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(random\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m6\u001b[39m))  \u001b[38;5;66;03m# Random delay to avoid detection\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Wait for new carousel posts to load\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m \u001b[43mWebDriverWait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muntil\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mEC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpresence_of_all_elements_located\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m//article//div[contains(@class, \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meLAPa\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m)]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# Increment scroll attempt count\u001b[39;00m\n\u001b[1;32m    112\u001b[0m scroll_attempt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ds4003/lib/python3.8/site-packages/selenium/webdriver/support/wait.py:105\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[0;34m(self, method, message)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll)\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[0;31mTimeoutException\u001b[0m: Message: \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from PIL import Image\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Function to take a screenshot and save it as a JPEG\n",
    "def screenshot_image_to_jpeg(image_element, dest_folder, image_id):\n",
    "    try:\n",
    "        # Get the location and size of the image element\n",
    "        location = image_element.location\n",
    "        size = image_element.size\n",
    "\n",
    "        # Take screenshot of the entire page\n",
    "        driver.save_screenshot(\"temp_screenshot.png\")\n",
    "\n",
    "        # Open the screenshot using PIL\n",
    "        image = Image.open(\"temp_screenshot.png\")\n",
    "\n",
    "        # Calculate the cropping box: (left, upper, right, lower)\n",
    "        left = location['x']\n",
    "        top = location['y']\n",
    "        right = left + size['width']\n",
    "        bottom = top + size['height']\n",
    "\n",
    "        # Crop the image to the bounds of the image element\n",
    "        image = image.crop((left, top, right, bottom))\n",
    "\n",
    "        # Convert to RGB if the image is not in RGB mode (necessary for saving as JPEG)\n",
    "        image = image.convert(\"RGB\")\n",
    "\n",
    "        # Ensure a unique name for each image (using image_id)\n",
    "        img_name = os.path.join(dest_folder, f\"carousel_image_{image_id}.jpg\")\n",
    "\n",
    "        # Check if the dest_folder is a valid directory before saving\n",
    "        if os.path.isdir(dest_folder):\n",
    "            image.save(img_name, \"JPEG\")\n",
    "            print(f\"Saved image {img_name}\")\n",
    "            return img_name  # Return file path for dataset\n",
    "        else:\n",
    "            print(f\"Error: The destination '{dest_folder}' is not a valid directory.\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to screenshot image. Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to capture images from a carousel post\n",
    "def capture_carousel_images(carousel_element, dest_folder, image_data):\n",
    "    try:\n",
    "        # Click on the carousel post to open it\n",
    "        carousel_element.click()\n",
    "\n",
    "        # Increase the wait time for the images in the carousel to load\n",
    "        WebDriverWait(driver, 60).until(\n",
    "            EC.presence_of_all_elements_located((By.XPATH, \"//div[@role='dialog']//img[contains(@src, 'https://')]\"))\n",
    "        )\n",
    "\n",
    "        # Find all the images in the carousel (this is the dialog box containing the carousel images)\n",
    "        carousel_images = driver.find_elements(By.XPATH, \"//div[@role='dialog']//img[contains(@src, 'https://')]\")\n",
    "        \n",
    "        # Loop through each image in the carousel and take a screenshot\n",
    "        for idx, img in enumerate(carousel_images):\n",
    "            img_path = screenshot_image_to_jpeg(img, dest_folder, len(image_data) + 1)\n",
    "            if img_path:\n",
    "                image_data.append({'image_path': img_path})  # Store image path in dataset\n",
    "            if len(image_data) >= 100:  # Limit to 100 images\n",
    "                break\n",
    "        \n",
    "        # Close the carousel dialog\n",
    "        close_button = driver.find_element(By.XPATH, \"//div[@role='dialog']//button[text()='Close']\")\n",
    "        close_button.click()\n",
    "        time.sleep(1)  # Allow time for the modal to close\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing carousel: {e}\")\n",
    "\n",
    "# Function to scroll the page and capture carousel images only\n",
    "def scroll_and_capture_carousel_images(max_images=100, scroll_max=10):\n",
    "    image_data = []\n",
    "    scroll_attempt = 0\n",
    "\n",
    "    while len(image_data) < max_images and scroll_attempt < scroll_max:\n",
    "        print(f\"Scraping carousel images, attempt {scroll_attempt + 1}...\")\n",
    "\n",
    "        # Find all carousel posts on the page (posts with multiple images)\n",
    "        carousels = driver.find_elements(By.XPATH, \"//article//div[contains(@class, 'eLAPa')]\")  # Carousel identifier\n",
    "\n",
    "        # Loop through each carousel and capture images\n",
    "        for carousel in carousels:\n",
    "            capture_carousel_images(carousel, dest_loc, image_data)\n",
    "\n",
    "            # Stop when we have captured enough images\n",
    "            if len(image_data) >= max_images:\n",
    "                print(f\"Reached {max_images} carousel images, stopping.\")\n",
    "                break\n",
    "\n",
    "        # Scroll down to load more carousels\n",
    "        driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "        time.sleep(random.uniform(3, 6))  # Random delay to avoid detection\n",
    "\n",
    "        # Wait for new carousel posts to load\n",
    "        WebDriverWait(driver, 60).until(\n",
    "            EC.presence_of_all_elements_located((By.XPATH, \"//article//div[contains(@class, 'eLAPa')]\"))\n",
    "        )\n",
    "\n",
    "        # Increment scroll attempt count\n",
    "        scroll_attempt += 1\n",
    "\n",
    "    return image_data\n",
    "\n",
    "# Define the directory path for saving images\n",
    "path = os.path.join(os.getenv('HOME'), \"Downloads\", \"siblingsordating\")  # macOS/Linux\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Start scraping and capturing carousel images only\n",
    "image_data = scroll_and_capture_carousel_images(max_images=100, scroll_max=10)\n",
    "\n",
    "# Convert the collected image file paths to a pandas DataFrame\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(image_data)\n",
    "\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "print(\"Scraping complete. Dataset saved as CSV and images saved as JPEG.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from PIL import Image\n",
    "import requests\n",
    "import pandas as pd\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_and_capture_images(max_images=100, scroll_max=10):\n",
    "    image_data = []\n",
    "    scroll_attempt = 0\n",
    "\n",
    "    while len(image_data) < max_images and scroll_attempt < scroll_max:\n",
    "        print(f\"Scraping images, attempt {scroll_attempt + 1}...\")\n",
    "\n",
    "        # Find all carousel posts (collections) on the page\n",
    "        carousels = driver.find_elements(By.XPATH, \"//div[contains(@class, 'eLAPa')]\")  # Updated XPath for carousels\n",
    "\n",
    "        # Capture images from each carousel\n",
    "        for carousel in carousels:\n",
    "            # Ensure images are being added to image_data\n",
    "            capture_carousel_images(carousel, dest_loc, image_data)\n",
    "\n",
    "            # Log how many images we have so far\n",
    "            print(f\"Found {len(image_data)} images so far...\")\n",
    "            \n",
    "            # Stop when we reach the max_images\n",
    "            if len(image_data) >= max_images:\n",
    "                print(f\"Reached {max_images} images, stopping.\")\n",
    "                break  # Stop after collecting the desired number of images\n",
    "\n",
    "        # Scroll down to load more images\n",
    "        driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "        time.sleep(random.uniform(3, 6))  # Random delay to avoid detection\n",
    "\n",
    "        # Wait for new images to load (important for dynamic content)\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//img[contains(@src, 'https://')]\")))\n",
    "\n",
    "        # Increment scroll attempt count\n",
    "        scroll_attempt += 1\n",
    "\n",
    "    return image_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.instagram.com/siblingsordating/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Go to the user's profile page\n",
    "profile_username = \"siblingsordating\"  # Replace with the Instagram account username\n",
    "driver.get(f\"https://www.instagram.com/{profile_username}/\")\n",
    "time.sleep(3)\n",
    "print(driver.current_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to the user's profile page\n",
    "profile_username = \"siblingsordating\"  # Replace with the Instagram account username\n",
    "driver.get(f\"https://www.instagram.com/{profile_username}/\")\n",
    "time.sleep(3)\n",
    "driver.execute_script(\"windowscrollTo(0,4000);\")\n",
    "images = driver.find_element_by_tag_name('img')\n",
    "images = [image.get_attribute('scr') for image in images]\n",
    "path = os.getcwd()\n",
    "path = os.path.join(path,\"syblingordating\")\n",
    "os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function posix.mkdir(path, mode=511, *, dir_fd=None)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = 0 \n",
    "for image in images:\n",
    "    save_as = os.path.join(path,\"syblingordating\" + str(counter) + '.jpeg')\n",
    "    wget.download(image, save_as)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mimg_name\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img_name' is not defined"
     ]
    }
   ],
   "source": [
    "print(img_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading MRI analysis package test "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds4003",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
